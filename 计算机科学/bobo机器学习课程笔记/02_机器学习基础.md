# 2 机器学习基础

## 2.1 机器学习世界的数据

我们以鸢尾花数据集为例

| 萼片长度 | 萼片宽度 | 花瓣长度 | 花瓣宽度 | 种类    |
| :--- | :--- | :--- | :--- | :---- |
| 5.1  | 3.5  | 1.4  | 0.2  | se(0) |
| 7.0  | 3.2  | 4.7  | 1.4  | ve(1) |
| 6.3  | 3.3  | 6    | 2.5  | vi(2) |

- 数据集(data set)：数据整体
- 样本(sample)：每一行数据称为一个样本
- 特征(feature)：除最后一列，每一列表达样本的一个特征
- 特征空间(feature)：特征向量所在的空间（分类的本质任务就是在特征空间切分）
- 标记(label)：最后一列称为标记

- X：整个表格除最后一列外，通常用X表示。X是个矩阵，行数即是样本数，列数即是特征数。
- y：最后一列一般用小写y表示，其实一个向量。
- X加上角标i：i是行号，称为特征向量。一般向量都是列向量，转置后即表示一行。

## 2.2 机器学习的主要任务

两类：分类、回归

这两种分类其实是监督学习的分类。除了监督学习之外的其他种类的机器学习还可以处理其他任务。本课程的主要内容包含在监督学习里。

### 分类任务

分类任务又可分为：

- 二分类：两种结果的分类
- 多分类：多种分类结果
- 多标签分类：把一个样本分类到多个标签下。

有些算法只能完成二分类的任务，但是多分类的任务是可以转化为二分类的任务的。

### 回归任务

分类任务中标签是离散的，而回归任务可以处理标签是连续的数据集，比如以房价为标签的房产数据集。

特点：结果是一个连续数字的值，而非一个类别

一些情况下，回归任务可以简化为分类任务。即将连续的结果划分为一个个离散的结果。


## 2.3 监督学习、非监督学习、半监督学习、增强学习

### 监督学习

- 特点：给机器的训练数据拥有“标记”或“答案”。既有数据特征，又有标记。监督的意思就是人类已经给数据进行了正确答案的划分。

我们在这个课程中学习的大部分算法，都属于监督学习算法

- k近邻
- 线性回归和多项式回归
- 逻辑回归
- SVM
- 决策树和随机森林

### 非监督学习

- 特点：给机器的训练数据没有任何“标记”或“答案”

非监督学习的作用：

- 聚类分析：对没有“标记”的数据进行分类
- 对数据进行降维处理：特征提取、特征压缩（尽量少的损失信息的情况下，把高维的特征向量压缩成低维的特征向量，如把二维的点变成一个直线，则变成了一维）。降维还可以方便数据可视化。
- 异常检测：数据中的异常点（和其他点距离很远）

### 半监督学习

- 特点：一部分数据有“标记”，另一部分没有

通常使用无监督学习手段对数据做处理，之后使用监督学习手段模型的训练和预测

### 增强学习

- 特点：根据周围环境情况，采取行动，根据采取行动的结果，学习行动方式。

应用：AlphaGo、无人驾驶、机器人

## 2.4 在线学习和批量学习、参数学习和非参数学习

### 在线学习和批量学习（离线学习）

- 批量学习：先训练好模型，然后投入生产。缺点是无法自动适应环境变化（有新特点的数据）
- 在线学习：把模型的预测结果和事实比较，并且把这个作为学习资料，又作为输入，迭代进行学习。

### 参数学习和非参数学习

- 参数学习：对模型有假设，（假设可以理解为函数的参数）一旦学到了参数，就不再需要原有的数据集
- 非参数学习：不对模型进行过多假设（但不是没有参数）

## 2.5 机器学习的哲学思考

传统算法都解决有确定答案的问题。而机器学习的算法面对的是高度不确定的世界，给出的答案也是具有概率意义和统计学意义上的答案。



